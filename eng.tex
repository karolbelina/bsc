\documentclass[english,engineering]{wizthesis}

\usepackage[utf8]{inputenc}
\usepackage{float} % H float positioning
\usepackage{xcolor}
\usepackage{enumitem} % enumerate
\usepackage{amsmath, bm}
\usepackage{mathtools}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{xspace}

% Set up the thesis
\author{Karol Belina}
\title{Formal grammar\par production rule parsing tool}
\supervisor{dr inż. Zdzisław Spławski}
\fieldofstudy{Computer Science}
\keywords{Parser combinators, context-free grammars, Extended Backus-Naur Form}
\summary{The thesis documents the process of designing and implementing a tool
for parsing the production rules of context-free grammars in a textual form. It
discusses the choice of Extended Backus-Naur Form notation over the alternatives
and provides a mathematical model for parsing such a notation. The implemented
parser can turn a high-level specification of a grammar into a parser itself,
which in turn is capable of constructing a parse tree from arbitrary input
provided to the program with the use of parser combinators.}

% Set up the style of code listings (optional)
\setminted{frame=single,breaklines,linenos}
% Set up the bibliography style
\bibliographystyle{acm}

\newcommand{\todo}[1]{%
  {\color{red}[\textbf{TODO}\ifx&#1&{}\else{ }\fi\emph{#1}]}%
}

\begin{document}

\frontmatter % Disable page and chapter numbering for this section

\maketitle

% '\chapter*' removes both abstracts from the table of contents
\chapter*{Abstract}

The thesis presents the design and implementation of a context-free grammar
parsing tool with real-time explanations and error detection. It discusses the
choice of Extended Backus-Naur Form notation over the alternatives and provides
a mathematical model for parsing such a notation. For this purpose, the official
specification of the EBNF from the ISO/IEC 14977 standard has been examined and
transformed into an unambiguous form. A definition of a grammar is proposed to
act as a result of the syntactic analysis phase formed with a technique called
\emph{parser combination}. A method of testing an arbitrary input against the
language generated by the constructed grammar is described. The thesis shows the
process of creating a simple command line REPL program to act as a basic tool
for interfacing with the grammar parser and checker, but in order to efficiently
use the library, a web-based application is designed on top of that to serve as
a more visual, user-friendly and easily accessible tool. It describes the
deployment of the application on a static site hosting service, as well as a
cross-platform desktop application. The designed and implemented system gives
the opportunity to extend it with other grammar specifications.

{\let\clearpage\relax % Keep the polish abstract on the same page
\chapter*{Streszczenie}

Praca przedstawia proces projektowania i~implementacji narzędzia służącego~do
analizy~syntaktycznej gramatyk~bezkontekstowych z~naciskiem na~obsługę błędów
i~wyjaśnień w czasie rzeczywistym. Omawia wybór rozszerzonej~notacji
Backusa-Naura i~przestawia matematyczny model do~analizy takiej notacji. W~tym
celu przeprowadzono analizę i~przekształcenie w jednoznaczną formę oficjalnej
jej specyfikacji zdefiniowanej w standardzie ISO/IEC~14977. Zaproponowana
zostaje definicja gramatyki tej notacji, która jest tworzona w wyniku analizy
syntaktycznej za pomocą techniki zwanej \emph{kombinacją~parserów}. Opisana
zostaje metoda sprawdzania dowolnego ciągu znaków pod kątem języka generowanego
przez analizowaną gramatykę. Praca przedstawia stworzenie prostego programu
działającego z~poziomu wiersza poleceń, który jest podstawowym narzędziem do
analizy gramatyk, jednak by móc efektywnie korzystać ze~stworzonej biblioteki,
zaprojektowana zostaje aplikacja webowa, która służy za bardziej wizualne,
przyjazne i łatwo dostępne dla użytkownika narzędzie. Praca opisuje wdrażanie
aplikacji na~usługę hostingową dla statycznych stron, a~także jako
wieloplatformowej aplikacji. Zaprojektowany i~wdrożony system daje możliwość
rozszerzenia go o~inne specyfikacje gramatyk.}

\tableofcontents

\mainmatter % Re-enable page and chapter numbering

\chapter{Problem analysis}

\section{Description and motivation} \label{sec:description-and-motivation}

Programming language theory has become a well-recognized branch of computer
science that deals with the study of programming languages and their
characteristics. It is an active research field, with findings published in
various journals, as well as general publications in computer science and
engineering. But besides the formal nature of Programming language theory, many
amateur programming language creators try their hand at the challenge of
creating a programming language of their own as a personal project. It is
certainly relevant for a person to write their own language for educational
purposes, and to learn about programming language and compiler design. However,
the language creator must first of all make some fundamental decisions about the
paradigms to be used, as well as the syntax of the language.

The tools for aiding the design and implementation of the syntax of a language
are generally called \emph{compiler-compilers}. These programs create parsers,
interpreters or compilers from some formal description of a programming
language (usually a grammar). The most commonly used types of
compiler-compilers are \emph{parser generators}, which handle only the
syntactic analysis of the language --- they do not handle the semantic analysis,
nor the code generation aspect. The parser generators most generally transform a
grammar of the syntax of a given programming language into a source code of a
parser for that language. The language of the source code for such a parser is
dependent on the parser generator.

Most such tools, however, \todo{offer} too much complexity and generally have a steep
learning curve for people inexperienced with the topic. Limited availability
makes them less fitted for prototyping a syntax of a language --- they often
require a complex setup for simple tasks, which is not welcoming for new users
\todo{and may lead to...?}. The lack of visualization capabilities shipped with
these tools makes them less desirable for teachers in the theory of formal
languages, who often require such features for educative purposes in order to
present the formulations of context-free grammars in a more visual format.

\section{Goal of the thesis}

The main goal of this thesis is to design and implement a specialized tool, that
serves teachers, programmers and other kinds of enthusiasts of the theory of
formal languages in the field of discrete mathematics and computer science, in
order to formulate and visualize context-free grammars in the form of the
Extended Backus-Naur Form. In order to \todo{}, the tool must provide a
graphical user interface. Additionally, to ensure the hightest degree of
accessibility, the tool must be available in the form of an easily accessible
web-based application that is accessed through a web page and can run in a
browser without the need of installation on the user's device. The thesis itself
will document the entire process of creating such a project.

\todo{jak projekt pomoże w powyższych problemach?}

In order to achieve the general goal, several sub-goals have been
distinguished, all of which contribute to the main objective as a whole
\begin{itemize}
  \item analysis of existing solutions and applications,
  \item presentation of the theoretical preliminaries of the project,
  \item definition of the outline of the project, including a description of
  the functional and non-functional requirements, the use case diagram, use case
  scenarios, the class diagram, and the user interface prototype,
  \item description of technologies used in the implementation,
  \item implementation of the project,
  \item description of the testing and deployment environments.
\end{itemize}

\section{Scope of the project}

The thesis will propose a definition of a grammar in the form of an abstract
syntax tree of the Extended Backus-Naur Form. It will describe the process of
implementing the business logic of the application in the Rust programming
language compiled to WebAssembly. The compiled code is then ran inside the
web-based application made with the Svelte framework, which incorporates the
markup, CSS styles, and JavaScript scripts in the superset of the HyperText
Markup Language (HTML).

The implementation phase will include the process of tokenization --- the act of
dividing the grammar in a textual form into a sequence of tokens --- while
taking into account proper interpretation of Unicode graphemes. The
whitespace-agnostic tokens will be then combined together to form a
previously-defined abstract syntax tree with a technique called \emph{parser
combination}. Several smaller helper parsers will be defined, all of which then
will be combined into more sophisticated parsers capable of parsing entire
terms, productions, and grammars. The implementation phase will also include the
definition of an algorithm for handling left recursion in the resulting grammar,
as well as a dependency graph reduction algorithm for determining the starting
rule of a grammar. Up to this stage, any errors encountered in the textual form
of a grammar are going to be reported to the user in a friendly format with
exact locations of the errors in the input.

\todo{\begin{itemize}[noitemsep,nolistsep]
  \item service workers
  \item wizualizacje, edytor tekstowy i kolorowanie składni
  \item wyjaśnienia zwracane przez checker?
  \item wyrażenia regularne w specjalnych sekwencjach?
\end{itemize}}

The web application will be deployed on the GitHub Pages hosting service for
static sites, as well as a standalone desktop application with the use of the
Electron framework.

\section{Glossary}

\begin{description}[leftmargin=!,labelwidth=2cm]
  \item[AST] Abstract syntax tree --- \todo{},
  \item[EBNF] Extended Backus-Naur Form --- \todo{},
  \item[parser] \todo{},
  \item[REPL] Read-Eval-Print loop --- \todo{}.
  \item \todo{}
\end{description}

\chapter{Theoretical preliminaries}

\section{Formal grammars}

\subsection{Introduction to formal grammars}

\emph{Formal grammar} of a language defines the construction of strings of
symbols from the language's \emph{alphabet} according to the language's
\emph{syntax}. It is a set of so-called \emph{production~rules} for
rewriting certain strings of symbols with other strings of symbols --- it can
therefore generate any string belonging to that language by repeatedly applying
these rules to a given starting symbol~\cite{meduna-2014}. Furthermore, a
grammar can also be applied in reverse: it can be determined if a string of
symbols belongs to a given language by breaking it down into its constituents
and analyzing them in the process known as \emph{parsing}.

For now, let's consider a simple example of a formal grammar. It consists of two
sets of symbols: (1) set $N = \{\,S, B\,\}$, whose symbols are
\emph{non-terminal} and must be rewritten into other, possibly non-terminal,
symbols, and (2) set $\Sigma = \{\,a, b, c\,\}$, whose symbols are
\emph{terminal} and cannot be rewritten further. Let $S$ be the start symbol
and set $P$ be the set of the following production rules:
\begin{enumerate}[noitemsep]
  \item $S \rightarrow aBSc$
  \item $S \rightarrow abc$
  \item $Ba \rightarrow aB$
  \item $Bb \rightarrow bb$
\end{enumerate}
To generate a string in this language, one must apply these rules (starting with
the start symbol) until a string consisting only of terminal symbols is
produced. A production rule is applied to a string by replacing an occurrence
of the production rule's left-hand side in the string by that production rule's
right-hand side. The simplest example of generating such a string would be
\begin{equation*}
  S \xRightarrow[2]{} \underline{abc}
\end{equation*}
where $P \xRightarrow[i]{} Q$ means that string $P$ generates the string $Q$
according to the production rule $i$, and the generated part of the string
is underlined.

By choosing a different sequence of production rules we can generate a different
string in that language
\begin{equation*}
\begin{split}
  S & \xRightarrow[1]{} \underline{aBSc} \\
    & \xRightarrow[2]{} aB\underline{abc}c \\
    & \xRightarrow[3]{} a\underline{aB}bcc \\
    & \xRightarrow[4]{} aa\underline{bb}cc
\end{split}
\end{equation*}

After examining further examples of strings generated by these production rules
we may come into a conclusion that this grammar generates the language
$\{\,a^nb^nc^n \mid n \ge 1\,\}$, where $x^n$ is a string of $n$ consecutive $x$'s.
It means that the language is the set of strings consisting of one or more
$a$'s, followed by the exact same number of $b$'s, then followed by the exact
same number of $c$'s.

Such a system provides us with a notation for describing a given
language formally. Such a language is a usually infinite set of finite-length
sequences of terminal symbols from that language.

\subsection{The Chomsky Hierarchy}

\begin{wrapfigure}{R}{0.45\textwidth}
  \centering
  \begin{tikzpicture}[scale=2.5]
    \draw[color=black](0,0) ellipse (1.25 and 1)
      node at (0, 0.68) {\small recursively enumerable};
    \draw[color=black](0,-0.2) ellipse (1 and 0.75)
      node at (0, 0.25) {\small context-sensitive};
    \draw[color=black](0,-0.4) ellipse (0.75 and 0.5)
      node at (0, -0.15) {\small context-free};
    \draw[color=black](0,-0.6) ellipse (0.5 and 0.25)
      node {\small regular};
  \end{tikzpicture}
  \caption{The~Chomsky~Hierarchy visualized}
  \label{fig:chomsky-hierarchy}
\end{wrapfigure}

In~\cite{chomsky-1956} Chomsky divides formal grammars into four classes and
classifies them in the now called \emph{Chomsky~Hierarchy}. Each class is a
subset of another, distinguished by the complexity.

Type-3 grammars generate the so-called \emph{regular~languages}. As described
in~\cite{aho-1990}, regular languages can be matched by
\emph{regular~expressions} and decided by a \emph{finite~state~automaton}.
They are the most restricting kinds of grammars, with its production rules
consisting of a single non-terminal on the left-hand side and a single terminal,
possibly followed by a single non-terminal on the right-hand side. Because of
their simplicity, regular languages are used for lexical analysis of programming
languages~\cite{johnson-1968}.

Type-2 grammars produce \emph{context-free~languages} and can be represented
as a \emph{pushdown~automaton} which is an automaton that can maintain its
state with the use of a stack. \todo{jak w stosie wygląda pamięć}

\subsection{Parsing Expression Grammars}

\todo{\url{https://en.wikipedia.org/wiki/Parsing_expression_grammar}}

\todo{\cite{ford-2004}}

\section{Why EBNF?}

\section{Modifying the specification}

\todo{analiza i zmodyfikowanie oficjalnej specyfikacji EBNF}

See appendix \ref{ch:modified-spec}.

\section{Methods of syntactic analysis} \label{sec:parsing}

\subsection{Bottom-up parsing}

\subsection{Top-down parsing and parser combination}

\todo{opisanie parser combinatorów (w Haskellu?) \cite{swierstra-2009}
\cite{leijen-2001} \cite{fokker-1995}}

\begin{equation*}
  \text{type}\ \text{Parser}\ a = \text{String} \rightarrow \text{Maybe}\ (a, \text{String})
\end{equation*}

\begin{listing}[H]
  \begin{minted}{haskell}
type Parser a = String -> Maybe (a, String)
  \end{minted}
  \caption{\todo{podpis}}
  \label{lst:parser-type}
\end{listing}

% \begin{listing}[H]
%   \begin{minted}{haskell}
% parse digit "123"
% -- Just ('1', "23")
%   \end{minted}
%   \caption{\todo{podpis}}
%   \label{lst:parcomb-example1}
% \end{listing}

% \begin{listing}[H]
%   \begin{minted}{haskell}
% parse (char 'a') "bcd"
% -- Nothing
%   \end{minted}
%   \caption{\todo{podpis}}
%   \label{lst:parcomb-example2}
% \end{listing}

% \begin{listing}[H]
%   \begin{minted}{haskell}
% parse (multiple (digit <|> letter)) "abc123"
% -- Just ("abc123", "")
%   \end{minted}
%   \caption{\todo{podpis}}
%   \label{lst:parcomb-example3}
% \end{listing}

\chapter{Analysis of similar solutions}

\section*{Coco/R}

\todo{\cite{coco/r}}

\section*{ANTLR}

\todo{\cite{antlr}}

\section*{Bison}

\todo{\cite{bison}}

\section*{PLY}

\todo{\cite{ply}}

\section*{Regex101}

\todo{\cite{regex101}}

\chapter{Design of the project}

\section{Requirements}

\subsection{Functional requirements}

\subsection{Non-functional requirements}

\section{Use cases}

\todo{diagram UML}
\todo{scenariusze przypadków użycia}

\section{The architecture}

\subsection{Used technologies}

\todo{Git}
\todo{Rust \cite{klabnik-2018}}
\todo{nom \cite{couprie-2015}}
\todo{Svelte \cite{svelte-docs}}
\todo{Rollup}
\todo{WebAssembly}

\subsection{Class diagram}

\todo{Diagram ``klas''}

\section{Interface prototype}

\todo{obrazki}

\chapter{Implementation of the project}

\section{Software environment}

\subsection*{Visual Studio Code}

\todo{konfiguracja, rozszerzenia}

\subsection*{Git and GitHub}

\todo{w jaki sposób używam Gita, GitHuba, jak używam branchy, issues, PR,
projektów}

\subsection*{Cargo}

\todo{konfiguracja Cargo, Clippy}

\subsection*{npm}

\subsection*{Rollup}

\section{Business logic}

\subsection{Grammar definition}

% \begin{listing}[H]
%   \inputminted[fontsize=\small]{haskell}
%   {listings/ast.hs}
%   \caption{\todo{podpis}}
%   \label{lst:ast}
% \end{listing}

\todo{opis}

\subsection{Lexical analyser}

\todo{krótko o ``algorytmie'' tokenizacji}

\subsection{Syntactic analyser}

\todo{zdefiniowanie ważnych parserów dla EBNF}

\subsection{Left recursion handling}

\todo{przedstawienie algorytmu do usuwania lewej rekurencji i wyjaśnienie po co}

% \begin{algorithm}[H]
%   \SetAlgoLined
%   \KwResult{The result}
%   initialization\;
%   \While{condition}{
%     instructions\;
%     \eIf{condition}{
%       instruction1\;
%       instruction2\;
%     }{
%       instruction3\;
%     }
%   }
%   \caption{Name of the algorithm}
% \end{algorithm}

\subsection{Dependency graph reduction}

\todo{przedstawienie algorytmu do wyszukania reguły początkowej}

\subsection{Grammar processing}

\todo{opisanie sposobu na sprawdzenie czy wejście należy do języka generowanego
przez gramatykę}

\section{Command line application}

\section{Web-based application}

\subsection{Linking the business logic}

\todo{jak się kompiluje Rusta do WebAssembly, czyli wasm-pack}

\subsection{Text editor}

\todo{CodeMirror}

\subsection{Visualizations}

\chapter{Testing}

\section{Business logic testing}

\subsection{Unit testing}

\todo{Cargo test}

\subsection{Benchmarking}

\section{UI testing}

\todo{Jest}

\chapter{Deployment}

\section{GitHub Pages}

\section{Electron}

{\backmatter % Disable this chapter number
\chapter{Summary}}

\bibliography{bibliography.bib}

\listoffigures

\listoftables

\listoflistings

\begin{appendices}

\chapter{Modified specification} \label{ch:modified-spec}

\begin{listing}[H]
  \inputminted[fontsize=\small]{lexers/ebnf_lexer.py:EbnfLexer -x}
  {listings/specification.ebnf}
  \caption{Modified version of the EBNF language specification defined in
  \cite{iso-14977}}
  \label{lst:specification}
\end{listing}

\end{appendices}

\end{document}
