\documentclass[english,engineering]{wizthesis}

\usepackage[utf8]{inputenc}
\usepackage{float} % H float positioning
\usepackage{xcolor}

% Set up the thesis
\author{Karol Belina}
\title{Formal grammar\par production rule parsing tool}
\supervisor{dr inż. Zdzisław Spławski}
\fieldofstudy{Computer Science}
\keywords{Parser combinators, context-free grammars, Extended Backus-Naur Form}
\summary{The paper documents the process of designing and implementing a tool
for parsing the production rules of context-free grammars in a textual form. It
discusses the choice of Extended Backus-Naur Form notation over the alternatives
and provides a mathematical model for parsing such a notation. The implemented
parser can turn a high-level specification of a grammar into a parser itself,
which in turn is capable of constructing a parse tree from arbitrary input
provided to the program with the use of parser combinators.}

% Set up the style of code listings (optional)
\setminted{frame=single,breaklines,linenos}
% Set up the bibliography style
\bibliographystyle{acm}

\newcommand{\todo}[1]{{\color{red}[\textbf{TODO} \textit{#1}]}}

\begin{document}

\frontmatter % Disable page and chapter numbering for this section

\maketitle

% '\chapter*' removes the abstract from the table of contents
\chapter*{Abstract}

The thesis presents the design and implementation of an EBNF-based context-free
grammar parsing tool with real-time explanations and error detection. It
discusses the choice of Extended Backus-Naur Form notation over the alternatives
and provides a mathematical model for parsing such a notation. For this purpose,
the official specification of the EBNF from the ISO/IEC 14977 standard has been
examined and transformed into an unambiguous and ready for implementation form.
The thesis proposes a definition of a grammar in the form of an abstract syntax
tree. It describes the process of tokenization --- the act of dividing the
grammar in a textual form into a sequence of tokens --- while taking into
account proper interpretation of Unicode graphemes. The whitespace-agnostic
tokens are then being combined together to form a previously-defined AST with a
technique called \textit{parser combination}. Several smaller helper parsers are
defined, all of which are then combined into more sophisticated parsers capable
of parsing entire terms, productions, and grammars. \todo{coś o regexach w
specjalnych sekwencjach?} The paper defines an algorithm for handling left
recursion in the resulting grammar defined by an AST, as well as a dependency
graph reduction algorithm for determining the starting rule of a grammar. Up to
this stage, any errors encountered in the textual form of a grammar are reported
to the user in a user-friendly format with exact locations of the errors in the
input. The paper thus compares several techniques of storing the locations of
individual tokens and AST nodes for the purposes of error reporting. Further,
the thesis describes a method of testing an arbitrary input against the
constructed grammar to determine if it belongs to the language generated by that
grammar.
\todo{tutaj prawdopodobnie coś o wyjaśnieniach zwracanych przez checker}
The thesis describes the process of creating a simple command line REPL program
to act as a basic tool for interfacing with the grammar parser and checker, but
in order to efficiently use the library, a web-based application is designed on
top of that to serve as a more visual, user-friendly and easily accessible tool.
\todo{tutaj coś o wizualizacjach, edytorze tesktowym i highlightowaniu} The
paper describes the deployment of the application on a static site hosting
service \todo{service workery}, as well as a cross-platform desktop application
with the use of Electron. The designed and implemented system gives the
opportunity to extend it with other grammar specifications.
\todo{poparafrazować ``The thesis describes...''}

\tableofcontents

\mainmatter % Re-enable page and chapter numbering

\chapter{Problem analysis}

\section{Description and motivation}

Programming language theory has become a well-recognized branch of computer
science that deals with the study of programming languages and their
characteristics. It is an active research field, with findings published in
various journals, as well as general publications in computer science and
engineering. But besides the formal nature of PLT, many amateur programming
language creators try their hand at the challenge of creating a programming
language of their own as a personal project. It is certainly relevant for a
person to write their own language for educational purposes, and to learn about
programming language and compiler design. However, the language creator must
first of all make some fundamental decisions about the paradigms to be used, as
well as the syntax of the language.

The tools for aiding the design and implementation of the syntax of a language
are generally called \textit{compiler-compilers}. These programs create parsers,
interpreters or compilers from some formal description of a programming
language (usually a grammar). The most commonly used types of
compiler-compilers are \textit{parser generators}, which handle only the
syntactic analysis of the language --- they do not handle the semantic analysis,
not the code generation aspect. The parser generators most generally transform a
grammar of the syntax of a given programming language into a source code of a
parser for that language. The language of the source code for such a parser is
dependent on the parser generator.

Most such tools, however, offer too much complexity and generally have a steep
learning curve for people inexperienced with the topic. Limited availability
makes them less fitted for prototyping a syntax of a language --- they often
require a complex setup for simple tasks, which is not welcoming for new users
\todo{and may lead to...?}. The lack of visualization capabilities shipped with
these tools makes them less desirable for teachers in the theory of formal
languages, who often require such features for educative purposes in order to
present the formulations of context-free grammars in a more visual format.

\section{Goal}

\todo{stworzenie aplikacji takiej i takiej}
\todo{udokumentowanie procesu projektowania i tworzenia takiej aplikacji}

\section{Scope}

\todo{na pewno zakres? czym to się w ogóle różni?}

\chapter{Analysis of similar solutions}

\section{Coco/R}

\todo{\cite{coco/r}}

\section{ANTLR}

\todo{\cite{antlr}}

\section{Lex and Yacc}

\todo{\cite{lex-yacc}}

\section{PLY}

\todo{\cite{ply}}

\section{Regex101}

\todo{\cite{regex101}}

\chapter{Theoretical preliminaries}

\section{Context-free grammars}

\todo{wstęp do gramatyk bezkontekstowych i ich notacji}

\section{Why EBNF?}

\section{Specification}

\todo{analiza i zmodyfikowanie oficjalnej specyfikacji EBNF}

\section{Grammar definition}

\todo{definicja gramatyki w formie AST w notacji Haskella}

\section{Lexical analysis}

\todo{krótko o ``algorytmie'' tokenizacji}

\section{Syntactic analysis}

\subsection{Methods}

\todo{o różnych metodach i podejściach do parsowania}

\subsection{Parser combination}

\todo{opisanie parser combinatorów w Haskellu \cite{swierstra-2009}
\cite{leijen-2001} \cite{fokker-1995}}

\subsection{Parser definitions}

\todo{zdefiniowanie ważnych parserów dla EBNF}

\section{Grammar preprocessing}

\subsection{Left recursion handling}

\todo{przedstawienie algorytmu do usuwania lewej rekurencji i wyjaśnienie po co}

\subsection{Dependency graph reduction}

\todo{przedstawienie algorytmu do wyszukania reguły początkowej}

\section{Grammar processing}

\todo{opisanie sposobu na sprawdzenie czy wejście należy do języka generowanego
przez gramatykę}

\chapter{Design}

\section{Requirements}

\subsection{Functional requirements}

\subsection{Non-functional requirements}

\section{Use cases}

\todo{diagram UML}
\todo{scenariusze przypadków użycia}

\section{The architecture}

\subsection{Used technologies}

\todo{Git}
\todo{Rust \cite{rust-book}}
\todo{nom \cite{couprie-2015}}
\todo{Svelte \cite{svelte-docs}}
\todo{Rollup}
\todo{WebAssembly}

\subsection{Class diagram}

\todo{Diagram ``klas''}

\section{Interface prototype}

\todo{obrazki}

\chapter{Implementation}

\section{Environment}

\subsection{Visual Studio Code}

\todo{konfiguracja, rozszerzenia}

\subsection{Git and GitHub}

\todo{w jaki sposób używam Gita, GitHuba, jak używam branchy, issues, PR,
projektów}

\subsection{Cargo}

\todo{konfiguracja Cargo, Clippy}

\subsection{npm}

\subsection{Rollup}

\section{Business logic}

\subsection{Lexer}

\subsection{Parser}

\subsection{Preprocessor}

\subsection{Checker}

\section{Command line application}

\section{Web-based application}

\subsection{Linking the business logic}

\todo{jak się kompiluje Rusta do WebAssembly, czyli wasm-pack}

\subsection{Text editor}

\todo{CodeMirror}

\subsection{Visualizations}

\chapter{Testing}

\section{Automated testing}

\subsection{Business logic testing}

\todo{Cargo test}

\subsection{UI testing}

\todo{Jest}

\section{Manual testing}

\chapter{Deployment}

\section{GitHub Pages}

\section{Electron}

{\backmatter % Disable this chapter number
\chapter{Summary}}

\bibliography{bibliography.bib}

\listoffigures

\listoftables

\listoflistings

\begin{appendices}

\chapter{Modified specification}

\begin{listing}[H]
  \inputminted[fontsize=\small]{lexers/ebnf_lexer.py:EbnfLexer -x}
  {listings/specification.ebnf}
  \caption{Modified version of the EBNF language specification defined in
  \cite{iso-14977}}
  \label{lst:specification}
\end{listing}

\end{appendices}

\end{document}
